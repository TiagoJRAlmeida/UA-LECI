{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabib\\AppData\\Local\\Temp\\ipykernel_320\\1459306574.py:2: DtypeWarning: Columns (16,21,22,27,28,31,42,43,51,54) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_transport = pd.read_csv(\"D:/Projeto PECI/Transport_Document_Data.csv\",sep=\";\")\n"
     ]
    }
   ],
   "source": [
    "#read files into pandas DataFrames\n",
    "df_transport = pd.read_csv(\"D:/Projeto PECI/Transport_Document_Data.csv\",sep=\";\")\n",
    "#df_departure = pd.read_csv(\"D:/Projeto PECI/Departure_Document_Data.csv\",sep=\";\")\n",
    "#df_standard = pd.read_csv(\"D:/Projeto PECI/Tabela_de_Agentes_Standardizados.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from strings_manipulation import *\n",
    "names = {i for i in df_transport[\"name\"]}\n",
    "\n",
    "parts = dict()\n",
    "\n",
    "for i in names:\n",
    "    name = unicodedata.normalize('NFKD', i).encode('ASCII', 'ignore').decode('ASCII')\n",
    "    \n",
    "    name = name.lower()\n",
    "\n",
    "    # Remove caracteres especiais como \"-\", \";\", \".\", \"_\", etc.\n",
    "    name = re.sub(r'[^a-z& ]', '', name)\n",
    "\n",
    "    word_split = name.split(\" \")\n",
    "\n",
    "    for j in word_split:\n",
    "        if len(j)>0:\n",
    "            if j in parts.keys():\n",
    "                parts[j] += 1\n",
    "            else:\n",
    "                parts[j] = 1\n",
    "\n",
    "parts = {key: val for key, val in sorted(parts.items(), key = lambda ele: ele[1], reverse = True)}\n",
    "\n",
    "with open(\"part_count.json\",\"w\") as f:\n",
    "    json.dump(parts,f,indent=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sinonims.json\",\"r\") as f:\n",
    "    sino = json.loads(f.read())\n",
    "\n",
    "fnames = {i for i in sino.keys()}\n",
    "fnames.update({j for i in sino.values() for j in i if len(i) > 0})\n",
    "nfnames = [i for i in df_transport[\"name\"] if i not in fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m nfnames:\n\u001b[0;32m      4\u001b[0m     name_info[i] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midentification_number\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;28mlist\u001b[39m(),\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentity_id\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;28mlist\u001b[39m(),\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype_identification_id\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;28mlist\u001b[39m(),\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_entity_id\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;28mlist\u001b[39m(),\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransport_document_id\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;28mlist\u001b[39m(),\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocument_transport_type_id\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;28mlist\u001b[39m()}\n\u001b[1;32m----> 6\u001b[0m nf_index \u001b[38;5;241m=\u001b[39m {i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m df_transport\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mdf_transport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mat\u001b[49m[i,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m nfnames}\n\u001b[0;32m      7\u001b[0m df_transport_nf \u001b[38;5;241m=\u001b[39m df_transport\u001b[38;5;241m.\u001b[39miloc[nf_index]\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(df_transport_nf\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n",
      "File \u001b[1;32mc:\\Users\\gabib\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexing.py:611\u001b[0m, in \u001b[0;36mIndexingMixin.at\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;124;03m    Access a group of rows and columns by label(s) or a boolean array.\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;124;03m    for more details and explanations of advanced indexing.\u001b[39;00m\n\u001b[0;32m    608\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    609\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _LocIndexer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 611\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mat\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _AtIndexer:\n\u001b[0;32m    613\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    614\u001b[0m \u001b[38;5;124;03m    Access a single value for a row/column label pair.\u001b[39;00m\n\u001b[0;32m    615\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;124;03m    4\u001b[39;00m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _AtIndexer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#create a dictionary with relevant information of every name in the dataset\n",
    "name_info = dict()\n",
    "for i in nfnames:\n",
    "    name_info[i] = {\"identification_number\":list(),\"entity_id\":list(),\"type_identification_id\":list(),\"function_entity_id\":list(),\"transport_document_id\":list(),\"document_transport_type_id\":list()}\n",
    "\n",
    "nf_index = {i for i in df_transport.index if df_transport.at[i,\"name\"] in nfnames}\n",
    "df_transport_nf = df_transport.iloc[nf_index]\n",
    "\n",
    "for i in range(df_transport_nf.shape[0]):\n",
    "    if df_transport_nf.at[i,\"name\"] in name_info.keys():\n",
    "        if not pd.isna(df_transport_nf.at[i,\"identification_number\"]):\n",
    "            if str(df_transport_nf.at[i,\"identification_number\"]) not in name_info[df_transport_nf.at[i,\"name\"]][\"identification_number\"]:\n",
    "                name_info[df_transport_nf.at[i,\"name\"]][\"identification_number\"].append(str(df_transport_nf.at[i,\"identification_number\"]))\n",
    "\n",
    "        if not pd.isna(df_transport_nf.at[i,\"entity_id\"]):\n",
    "            if df_transport_nf.at[i,\"entity_id\"] not in name_info[df_transport_nf.at[i,\"name\"]][\"entity_id\"]:\n",
    "                name_info[df_transport_nf.at[i,\"name\"]][\"entity_id\"].append(df_transport_nf.at[i,\"entity_id\"])\n",
    "\n",
    "        if not pd.isna(df_transport_nf.at[i,\"type_identification_id\"]):\n",
    "            if df_transport_nf.at[i,\"type_identification_id\"] not in name_info[df_transport_nf.at[i,\"name\"]][\"type_identification_id\"]:\n",
    "                name_info[df_transport_nf.at[i,\"name\"]][\"type_identification_id\"].append(df_transport_nf.at[i,\"type_identification_id\"])\n",
    "\n",
    "        if not pd.isna(df_transport_nf.at[i,\"function_entity_id\"]):\n",
    "            if df_transport_nf.at[i,\"function_entity_id\"] not in name_info[df_transport_nf.at[i,\"name\"]][\"function_entity_id\"]:\n",
    "                name_info[df_transport_nf.at[i,\"name\"]][\"function_entity_id\"].append(df_transport_nf.at[i,\"function_entity_id\"])\n",
    "\n",
    "        if not pd.isna(df_transport_nf.at[i,\"transport_document_id\"]):\n",
    "            if df_transport_nf.at[i,\"transport_document_id\"] not in name_info[df_transport_nf.at[i,\"name\"]][\"transport_document_id\"]:\n",
    "                name_info[df_transport_nf.at[i,\"name\"]][\"transport_document_id\"].append(df_transport_nf.at[i,\"transport_document_id\"])\n",
    "        \n",
    "        if not pd.isna(df_transport_nf.at[i,\"document_transport_type_id\"]):\n",
    "            if df_transport_nf.at[i,\"document_transport_type_id\"] not in name_info[df_transport_nf.at[i,\"name\"]][\"document_transport_type_id\"]:\n",
    "                name_info[df_transport_nf.at[i,\"name\"]][\"document_transport_type_id\"].append(df_transport_nf.at[i,\"document_transport_type_id\"])\n",
    "                \n",
    "with open(\"name_information_not_found.json\",\"w\") as file:\n",
    "    json.dump(name_info,file,indent=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_info = dict()\n",
    "for i in range(df_transport.shape[0]):\n",
    "    name_info[df_transport.at[i,\"name\"]] = {\"identification_number\":list(),\"entity_id\":list(),\"type_identification_id\":list()}\n",
    "\n",
    "for i in range(df_transport.shape[0]):\n",
    "    if df_transport.at[i,\"name\"] in name_info.keys():\n",
    "        if not pd.isna(df_transport.at[i,\"identification_number\"]):\n",
    "            if str(df_transport.at[i,\"identification_number\"]) not in name_info[df_transport.at[i,\"name\"]][\"identification_number\"]:\n",
    "                name_info[df_transport.at[i,\"name\"]][\"identification_number\"].append(str(df_transport.at[i,\"identification_number\"]))\n",
    "\n",
    "        if not pd.isna(df_transport.at[i,\"entity_id\"]):\n",
    "            if df_transport.at[i,\"entity_id\"] not in name_info[df_transport.at[i,\"name\"]][\"entity_id\"]:\n",
    "                name_info[df_transport.at[i,\"name\"]][\"entity_id\"].append(df_transport.at[i,\"entity_id\"])\n",
    "\n",
    "        if not pd.isna(df_transport.at[i,\"type_identification_id\"]):\n",
    "            if df_transport.at[i,\"type_identification_id\"] not in name_info[df_transport.at[i,\"name\"]][\"type_identification_id\"]:\n",
    "                name_info[df_transport.at[i,\"name\"]][\"type_identification_id\"].append(df_transport.at[i,\"type_identification_id\"])\n",
    "                \n",
    "with open(\"name_information.json\",\"w\") as file:\n",
    "    json.dump(name_info,file,indent=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"name_information.json\",\"r\") as f:\n",
    "    names_load = json.loads(f.read())\n",
    "\n",
    "for i in range(df_departure.shape[0]):\n",
    "    if df_departure.at[i,\"name\"] not in names_load.keys():\n",
    "        names_load[df_departure.at[i,\"name\"]] = {\"identification_number\":list(),\"entity_id\":list(),\"type_identification_id\":list()}\n",
    "\n",
    "for i in range(df_departure.shape[0]):\n",
    "    if df_departure.at[i,\"name\"] in names_load.keys():\n",
    "        if not pd.isna(df_departure.at[i,\"identification_number\"]):\n",
    "            if str(df_departure.at[i,\"identification_number\"]) not in names_load[df_departure.at[i,\"name\"]][\"identification_number\"]:\n",
    "                names_load[df_departure.at[i,\"name\"]][\"identification_number\"].append(str(df_departure.at[i,\"identification_number\"]))\n",
    "                \n",
    "        if not pd.isna(df_departure.at[i,\"entity_id\"]):\n",
    "            if df_departure.at[i,\"entity_id\"] not in names_load[df_departure.at[i,\"name\"]][\"entity_id\"]:\n",
    "                names_load[df_departure.at[i,\"name\"]][\"entity_id\"].append(df_departure.at[i,\"entity_id\"])\n",
    "                \n",
    "with open(\"name_information.json\",\"w\") as file:\n",
    "    json.dump(names_load,file,indent=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sinonims = dict()\n",
    "with open(\"name_information.json\",\"r\") as f:\n",
    "    names_load = json.loads(f.read())\n",
    "\n",
    "for i in range(df_standard.shape[0]):\n",
    "    sinonims[df_standard.at[i,\"name\"]] = list()\n",
    "\n",
    "for i in range(df_standard.shape[0]):\n",
    "    for j in names_load.keys():\n",
    "        if str(df_standard.at[i,\"identification_number\"]) in names_load[j][\"identification_number\"]:\n",
    "            if j not in sinonims[df_standard.at[i,\"name\"]]:\n",
    "                sinonims[df_standard.at[i,\"name\"]].append(j)\n",
    "        \n",
    "        if df_standard.at[i,\"id\"] in names_load[j][\"entity_id\"]:\n",
    "            if j not in sinonims[df_standard.at[i,\"name\"]]:\n",
    "                sinonims[df_standard.at[i,\"name\"]].append(j)\n",
    "\n",
    "with open(\"sinonims.json\",\"w\") as file:\n",
    "    json.dump(sinonims,file,indent=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sinonims.json\",\"r\") as file:\n",
    "    sinonm = json.loads(file.read())\n",
    "\n",
    "sin = [i for i in sinonm.keys()]\n",
    "\n",
    "sin.extend([j for i in sinonm.values() for j in i if len(i) > 0])\n",
    "\n",
    "found_ids = set()\n",
    "for i in df_transport.index:\n",
    "    if df_transport.at[i,\"name\"] in sin:\n",
    "        found_ids.add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df_transport.iloc[[i for i in found_ids]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A Notificar',\n",
       " 'A Notificar 1',\n",
       " 'Agente Carga',\n",
       " 'Carregador',\n",
       " 'Consignatário',\n",
       " 'Original Shipper',\n",
       " 'Transportador'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{i for i in dataset[\"description\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[dataset[\"description\"] != \"A Notificar 1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[dataset[\"description\"] != \"A Notificar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt2 = df_departure.copy()\n",
    "dt2 = dt2[dt2[\"description\"] != \"A Notificar 1\"]\n",
    "dt2 = dt2.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 393. MiB for an array with shape (13, 3962956) and data type object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m le \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[0;32m      5\u001b[0m categorical_features \u001b[38;5;241m=\u001b[39m dt2\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m----> 7\u001b[0m d_copy \u001b[38;5;241m=\u001b[39m \u001b[43mdt2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m categorical_features:\n\u001b[0;32m     10\u001b[0m     d_copy[feature] \u001b[38;5;241m=\u001b[39m le\u001b[38;5;241m.\u001b[39mfit_transform(d_copy[feature])\n",
      "File \u001b[1;32mc:\\Users\\gabib\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:6811\u001b[0m, in \u001b[0;36mNDFrame.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m   6662\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   6663\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcopy\u001b[39m(\u001b[38;5;28mself\u001b[39m, deep: bool_t \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m   6664\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   6665\u001b[0m \u001b[38;5;124;03m    Make a copy of this object's indices and data.\u001b[39;00m\n\u001b[0;32m   6666\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6809\u001b[0m \u001b[38;5;124;03m    dtype: int64\u001b[39;00m\n\u001b[0;32m   6810\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 6811\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6812\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n\u001b[0;32m   6813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(data, axes\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[0;32m   6814\u001b[0m         \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcopy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6815\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\gabib\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:593\u001b[0m, in \u001b[0;36mBaseBlockManager.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    590\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    591\u001b[0m         new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m--> 593\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcopy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    594\u001b[0m res\u001b[38;5;241m.\u001b[39maxes \u001b[38;5;241m=\u001b[39m new_axes\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    597\u001b[0m     \u001b[38;5;66;03m# Avoid needing to re-compute these\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gabib\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32mc:\\Users\\gabib\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:796\u001b[0m, in \u001b[0;36mBlock.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    794\u001b[0m refs: BlockValuesRefs \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    795\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 796\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    797\u001b[0m     refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    798\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 393. MiB for an array with shape (13, 3962956) and data type object"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Convert categorical variables to numerical values\n",
    "le = LabelEncoder()\n",
    "categorical_features = dt2.columns\n",
    "\n",
    "d_copy = dt2.copy()\n",
    "\n",
    "for feature in categorical_features:\n",
    "    d_copy[feature] = le.fit_transform(d_copy[feature])\n",
    "\n",
    "print(d_copy.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5222681237914627\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Extract features and labels\n",
    "X = d_copy.drop('description', axis=1)\n",
    "y = d_copy['description']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the Gaussian Naive Bayes classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Train the model\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dataset.index:\n",
    "    for j in dataset.columns:\n",
    "        if dataset.at[i,j] == np.nan:\n",
    "            dataset.at[i,j] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2147913, 70)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[dataset.isna()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#divide dataset for training and testing the model\n",
    "X = dataset.drop('description', axis=1)\n",
    "y = np.array(dataset['description'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [69, 1503539]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 11\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TfidfTransformer\n\u001b[0;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m Pipeline([(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvect\u001b[39m\u001b[38;5;124m'\u001b[39m, CountVectorizer()),\n\u001b[0;32m      7\u001b[0m                 (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtfidf\u001b[39m\u001b[38;5;124m'\u001b[39m, TfidfTransformer()),\n\u001b[0;32m      8\u001b[0m                 (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclf\u001b[39m\u001b[38;5;124m'\u001b[39m, SGDClassifier(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhinge\u001b[39m\u001b[38;5;124m'\u001b[39m, penalty\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m'\u001b[39m,alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m      9\u001b[0m                ])\n\u001b[1;32m---> 11\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     15\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n",
      "File \u001b[1;32mc:\\Users\\gabib\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gabib\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py:473\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    472\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m routed_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 473\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\gabib\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gabib\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:938\u001b[0m, in \u001b[0;36mBaseSGDClassifier.fit\u001b[1;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m    909\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit linear model with Stochastic Gradient Descent.\u001b[39;00m\n\u001b[0;32m    910\u001b[0m \n\u001b[0;32m    911\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;124;03m    Returns an instance of self.\u001b[39;00m\n\u001b[0;32m    935\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    936\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_more_validate_params()\n\u001b[1;32m--> 938\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    939\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    941\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    942\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoef_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintercept_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mintercept_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gabib\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:725\u001b[0m, in \u001b[0;36mBaseSGDClassifier._fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m    722\u001b[0m \u001b[38;5;66;03m# Clear iteration count for multiple call to fit.\u001b[39;00m\n\u001b[0;32m    723\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m--> 725\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_partial_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    727\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    728\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    732\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintercept_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    737\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    740\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    741\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter\n\u001b[0;32m    743\u001b[0m ):\n\u001b[0;32m    744\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    745\u001b[0m         (\n\u001b[0;32m    746\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaximum number of iteration reached before \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    750\u001b[0m         ConvergenceWarning,\n\u001b[0;32m    751\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\gabib\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:596\u001b[0m, in \u001b[0;36mBaseSGDClassifier._partial_fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, max_iter, classes, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[0;32m    581\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_partial_fit\u001b[39m(\n\u001b[0;32m    582\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    583\u001b[0m     X,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    593\u001b[0m     intercept_init,\n\u001b[0;32m    594\u001b[0m ):\n\u001b[0;32m    595\u001b[0m     first_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclasses_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 596\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    604\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    606\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m first_call:\n\u001b[0;32m    607\u001b[0m         \u001b[38;5;66;03m# TODO(1.7) remove 0 from average parameter constraint\u001b[39;00m\n\u001b[0;32m    608\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maverage, (\u001b[38;5;28mbool\u001b[39m, np\u001b[38;5;241m.\u001b[39mbool_)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maverage \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\gabib\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\gabib\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1320\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1301\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1302\u001b[0m     X,\n\u001b[0;32m   1303\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1316\u001b[0m )\n\u001b[0;32m   1318\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m-> 1320\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32mc:\\Users\\gabib\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    460\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [69, 1503539]"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "model = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "               ])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                    995b7bb2-50af-443f-9229-8da3b8c1bf19\n",
       "creation_date                      2023-06-15 11:41:22.177\n",
       "version_date                       2023-06-15 11:50:06.037\n",
       "version_number                                           4\n",
       "business_entity_id    c675b807-6a70-4e06-8973-66084fe8b3ad\n",
       "                                      ...                 \n",
       "code                                                    CA\n",
       "description                                  Transportador\n",
       "enabled                                                  1\n",
       "goods_movement                                           1\n",
       "manifest                                               1.0\n",
       "Name: 2420981, Length: 70, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[1503539]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_found_count = {key: val for key, val in sorted(not_found_count.items(), key = lambda x: x[1] ,reverse=True)}\n",
    "\n",
    "with open(\"not_found_count.json\",\"w\") as f:\n",
    "    json.dump(not_found_count,f,indent=6)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2186292"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"sinonims.json\",\"r\") as f:\n",
    "    sinons = json.loads(f.read())\n",
    "\n",
    "sinonm = [j for i in sinons.values() for j in i if len(i) > 0]\n",
    "\n",
    "count = 0\n",
    "not_found = set() #nomes nao identificados\n",
    "\n",
    "for i in range(df_transport.shape[0]):\n",
    "    if df_transport.at[i,\"name\"] in sinonm:\n",
    "        count += 1\n",
    "    else:\n",
    "        not_found.add(df_transport.at[i,\"name\"])\n",
    "\n",
    "\n",
    "count\n",
    "#linhas corrigiveis 2424712"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2424712"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "238420 + 2186292"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: SyntaxWarning: invalid escape sequence '\\W'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\W'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\W'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\W'\n",
      "C:\\Users\\gabib\\AppData\\Local\\Temp\\ipykernel_18108\\2206320786.py:7: SyntaxWarning: invalid escape sequence '\\W'\n",
      "  not_found_info[re.sub('[\\W_]+', '',i)] = names_info_nf[re.sub('[\\W_]+', '',i)]\n",
      "C:\\Users\\gabib\\AppData\\Local\\Temp\\ipykernel_18108\\2206320786.py:7: SyntaxWarning: invalid escape sequence '\\W'\n",
      "  not_found_info[re.sub('[\\W_]+', '',i)] = names_info_nf[re.sub('[\\W_]+', '',i)]\n"
     ]
    }
   ],
   "source": [
    "with open(\"name_information.json\",\"r\") as f:\n",
    "    names_info_nf = json.loads(f.read())\n",
    "\n",
    "not_found_info = dict()\n",
    "\n",
    "for i in not_found:\n",
    "    not_found_info[re.sub('[\\W_]+', '',i)] = names_info_nf[re.sub('[\\W_]+', '',i)]\n",
    "\n",
    "with open(\"not_found.json\",\"w\") as f:\n",
    "    json.dump(not_found_info,f,indent=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_id</th>\n",
       "      <th>entity_id</th>\n",
       "      <th>name</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>identification_number</th>\n",
       "      <th>standard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9b884087-630b-429a-b211-14e06e15bc15</td>\n",
       "      <td>28d67639-ac25-42a8-8048-af9d5a7860fd</td>\n",
       "      <td>sacor marítima, s.a.</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>500237913</td>\n",
       "      <td>sacor marítima, s.a.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9b884087-630b-429a-b211-14e06e15bc15</td>\n",
       "      <td>e76f5c80-8876-4c31-be77-0070f7a9740b</td>\n",
       "      <td>navex - emp. portuguesa de navegação, s.a.</td>\n",
       "      <td>Sines</td>\n",
       "      <td>500200874</td>\n",
       "      <td>navex - emp. portuguesa de navegação, s.a.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>9b884087-630b-429a-b211-14e06e15bc15</td>\n",
       "      <td>0c630ec2-5067-4a94-b921-68cb6fa62318</td>\n",
       "      <td>dsv air and sea portugal, lda</td>\n",
       "      <td>2600-638</td>\n",
       "      <td>504638610</td>\n",
       "      <td>dsv air and sea portugal, lda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>9b884087-630b-429a-b211-14e06e15bc15</td>\n",
       "      <td>0c630ec2-5067-4a94-b921-68cb6fa62318</td>\n",
       "      <td>dsv air and sea portugal, lda</td>\n",
       "      <td>2600-638</td>\n",
       "      <td>504638610</td>\n",
       "      <td>dsv air and sea portugal, lda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6323</th>\n",
       "      <td>9b884087-630b-429a-b211-14e06e15bc15</td>\n",
       "      <td>2941a3f1-46b3-4c36-9468-dfbfb253e88b</td>\n",
       "      <td>gallo worldwide, lda</td>\n",
       "      <td>1070-184</td>\n",
       "      <td>508966442</td>\n",
       "      <td>gallo worldwide, lda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3438744</th>\n",
       "      <td>9b884087-630b-429a-b211-14e06e15bc15</td>\n",
       "      <td>2941a3f1-46b3-4c36-9468-dfbfb253e88b</td>\n",
       "      <td>gallo worldwide, lda</td>\n",
       "      <td>1070-184</td>\n",
       "      <td>508966442</td>\n",
       "      <td>gallo worldwide, lda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3438783</th>\n",
       "      <td>9b884087-630b-429a-b211-14e06e15bc15</td>\n",
       "      <td>2941a3f1-46b3-4c36-9468-dfbfb253e88b</td>\n",
       "      <td>gallo worldwide, lda</td>\n",
       "      <td>1070-184</td>\n",
       "      <td>508966442</td>\n",
       "      <td>gallo worldwide, lda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3438784</th>\n",
       "      <td>9b884087-630b-429a-b211-14e06e15bc15</td>\n",
       "      <td>2941a3f1-46b3-4c36-9468-dfbfb253e88b</td>\n",
       "      <td>gallo worldwide, lda</td>\n",
       "      <td>1070-184</td>\n",
       "      <td>508966442</td>\n",
       "      <td>gallo worldwide, lda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3438799</th>\n",
       "      <td>9b884087-630b-429a-b211-14e06e15bc15</td>\n",
       "      <td>2941a3f1-46b3-4c36-9468-dfbfb253e88b</td>\n",
       "      <td>gallo worldwide, lda</td>\n",
       "      <td>1070-184</td>\n",
       "      <td>508966442</td>\n",
       "      <td>gallo worldwide, lda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3438800</th>\n",
       "      <td>9b884087-630b-429a-b211-14e06e15bc15</td>\n",
       "      <td>2941a3f1-46b3-4c36-9468-dfbfb253e88b</td>\n",
       "      <td>gallo worldwide, lda</td>\n",
       "      <td>1070-184</td>\n",
       "      <td>508966442</td>\n",
       "      <td>gallo worldwide, lda</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9700 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   country_id  \\\n",
       "9        9b884087-630b-429a-b211-14e06e15bc15   \n",
       "10       9b884087-630b-429a-b211-14e06e15bc15   \n",
       "1248     9b884087-630b-429a-b211-14e06e15bc15   \n",
       "1249     9b884087-630b-429a-b211-14e06e15bc15   \n",
       "6323     9b884087-630b-429a-b211-14e06e15bc15   \n",
       "...                                       ...   \n",
       "3438744  9b884087-630b-429a-b211-14e06e15bc15   \n",
       "3438783  9b884087-630b-429a-b211-14e06e15bc15   \n",
       "3438784  9b884087-630b-429a-b211-14e06e15bc15   \n",
       "3438799  9b884087-630b-429a-b211-14e06e15bc15   \n",
       "3438800  9b884087-630b-429a-b211-14e06e15bc15   \n",
       "\n",
       "                                    entity_id  \\\n",
       "9        28d67639-ac25-42a8-8048-af9d5a7860fd   \n",
       "10       e76f5c80-8876-4c31-be77-0070f7a9740b   \n",
       "1248     0c630ec2-5067-4a94-b921-68cb6fa62318   \n",
       "1249     0c630ec2-5067-4a94-b921-68cb6fa62318   \n",
       "6323     2941a3f1-46b3-4c36-9468-dfbfb253e88b   \n",
       "...                                       ...   \n",
       "3438744  2941a3f1-46b3-4c36-9468-dfbfb253e88b   \n",
       "3438783  2941a3f1-46b3-4c36-9468-dfbfb253e88b   \n",
       "3438784  2941a3f1-46b3-4c36-9468-dfbfb253e88b   \n",
       "3438799  2941a3f1-46b3-4c36-9468-dfbfb253e88b   \n",
       "3438800  2941a3f1-46b3-4c36-9468-dfbfb253e88b   \n",
       "\n",
       "                                               name postal_code  \\\n",
       "9                              sacor marítima, s.a.      Lisboa   \n",
       "10       navex - emp. portuguesa de navegação, s.a.       Sines   \n",
       "1248                  dsv air and sea portugal, lda    2600-638   \n",
       "1249                  dsv air and sea portugal, lda    2600-638   \n",
       "6323                           gallo worldwide, lda    1070-184   \n",
       "...                                             ...         ...   \n",
       "3438744                        gallo worldwide, lda    1070-184   \n",
       "3438783                        gallo worldwide, lda    1070-184   \n",
       "3438784                        gallo worldwide, lda    1070-184   \n",
       "3438799                        gallo worldwide, lda    1070-184   \n",
       "3438800                        gallo worldwide, lda    1070-184   \n",
       "\n",
       "        identification_number                                    standard  \n",
       "9                   500237913                        sacor marítima, s.a.  \n",
       "10                  500200874  navex - emp. portuguesa de navegação, s.a.  \n",
       "1248                504638610               dsv air and sea portugal, lda  \n",
       "1249                504638610               dsv air and sea portugal, lda  \n",
       "6323                508966442                        gallo worldwide, lda  \n",
       "...                       ...                                         ...  \n",
       "3438744             508966442                        gallo worldwide, lda  \n",
       "3438783             508966442                        gallo worldwide, lda  \n",
       "3438784             508966442                        gallo worldwide, lda  \n",
       "3438799             508966442                        gallo worldwide, lda  \n",
       "3438800             508966442                        gallo worldwide, lda  \n",
       "\n",
       "[9700 rows x 6 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[215], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m Pipeline([(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvect\u001b[39m\u001b[38;5;124m'\u001b[39m, CountVectorizer()),\n\u001b[0;32m      2\u001b[0m                 (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtfidf\u001b[39m\u001b[38;5;124m'\u001b[39m, TfidfTransformer()),\n\u001b[0;32m      3\u001b[0m                 (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclf\u001b[39m\u001b[38;5;124m'\u001b[39m, SGDClassifier(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhinge\u001b[39m\u001b[38;5;124m'\u001b[39m, penalty\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m'\u001b[39m,alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m      4\u001b[0m                ])\n\u001b[1;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\gabib\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gabib\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py:473\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    472\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m routed_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 473\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\gabib\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gabib\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:938\u001b[0m, in \u001b[0;36mBaseSGDClassifier.fit\u001b[1;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m    909\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit linear model with Stochastic Gradient Descent.\u001b[39;00m\n\u001b[0;32m    910\u001b[0m \n\u001b[0;32m    911\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;124;03m    Returns an instance of self.\u001b[39;00m\n\u001b[0;32m    935\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    936\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_more_validate_params()\n\u001b[1;32m--> 938\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    939\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    941\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    942\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoef_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintercept_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mintercept_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gabib\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705\u001b[0m, in \u001b[0;36mBaseSGDClassifier._fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# labels can be encoded as float, int, or string literals\u001b[39;00m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;66;03m# np.unique sorts in asc order; largest class id is positive class\u001b[39;00m\n\u001b[0;32m    704\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(y\u001b[38;5;241m=\u001b[39my)\n\u001b[1;32m--> 705\u001b[0m classes \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    707\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarm_start \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoef_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    708\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m coef_init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\gabib\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[0;32m    272\u001b[0m ar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(ar)\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mequal_nan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[0;32m    278\u001b[0m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gabib\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\arraysetops.py:336\u001b[0m, in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[0;32m    334\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar[perm]\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 336\u001b[0m     \u001b[43mar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    337\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar\n\u001b[0;32m    338\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(aux\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mbool_)\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "model = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "               ])\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
